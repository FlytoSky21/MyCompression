[net]
# Testing
#batch=1
#subdivisions=1
# Training
batch=16
subdivisions=1
width=416
height=416
channels=3
momentum=0.9
decay=0.0005
angle=0
saturation = 1.5
exposure = 1.5
hue=.1

learning_rate=0.0001
burn_in=1000
max_batches = 500200
policy=steps
steps=400000,450000
scales=.1,.1

# 1
[convolutional]
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=leaky

# Downsample
# 2
[convolutional]
batch_normalize=1
filters=64
size=3
stride=2
pad=1
activation=leaky

# 3
[convolutional]
batch_normalize=1
filters=32
size=1
stride=1
pad=1
activation=leaky

# 4
[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky
# 5
[shortcut]
from=-3
activation=linear

# Downsample

# 6
[convolutional]
batch_normalize=1
filters=128
size=3
stride=2
pad=1
activation=leaky

# 7
[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

# 8
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

# 9
[shortcut]
from=-3
activation=linear


# 10
[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

# 11
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

# 12
[shortcut]
from=-3
activation=linear

# Downsample
# 13
[convolutional]
batch_normalize=1
filters=256
size=3
stride=2
pad=1
activation=leaky

